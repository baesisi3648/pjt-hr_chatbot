import os
import re
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_core.documents import Document
from pinecone import Pinecone, ServerlessSpec

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "company-rules")
NAMESPACE = "rules-2025"

def parse_rules(file_path):
    """
    í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ 'ì œNì¡°' ë‹¨ìœ„ë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
    """
    with open(file_path, "r", encoding="utf-8") as f:
        full_text = f.read()

    # ì •ê·œí‘œí˜„ì‹: "ì œ1ì¡°", "ì œ 2 ì¡°" ë“± ì¡°í•­ ì‹œì‘ íŒ¨í„´ ê°ì§€
    # íŒ¨í„´ ì„¤ëª…: ì¤„ë°”ê¿ˆ ë’¤ì— 'ì œ', ìˆ«ì, 'ì¡°' ê°€ ì˜¤ëŠ” ê²½ìš°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìë¦„
    pattern = r'(\n|^)ì œ\s?\d+\s?ì¡°'
    
    # splitìœ¼ë¡œ ë‚˜ëˆ„ë©´ [ë‚´ìš©, ì¡°í•­ì œëª©, ë‚´ìš©, ì¡°í•­ì œëª©...] ìˆœì„œë¡œ ë‚˜ì˜´
    # ì¢€ ë” ì‰¬ìš´ ì²˜ë¦¬ë¥¼ ìœ„í•´ 'ì œNì¡°' ìœ„ì¹˜ë¥¼ ì°¾ì•„ ìˆ˜ë™ìœ¼ë¡œ ìŠ¬ë¼ì´ì‹±í•©ë‹ˆë‹¤.
    matches = list(re.finditer(pattern, full_text))
    
    documents = []
    for i, match in enumerate(matches):
        start = match.start()
        # ë‹¤ìŒ ì¡°í•­ ì‹œì‘ ì „ê¹Œì§€ê°€ í˜„ì¬ ì¡°í•­ì˜ ë‚´ìš©
        end = matches[i+1].start() if i+1 < len(matches) else len(full_text)
        
        content = full_text[start:end].strip()
        
        # ì²« ë²ˆì§¸ ì¤„(ì˜ˆ: ì œ1ì¡°(ëª©ì ))ì„ ì¶”ì¶œí•˜ì—¬ ë©”íƒ€ë°ì´í„°ë¡œ í™œìš©
        lines = content.split('\n')
        title = lines[0].strip() if lines else "Unknown"
        
        # ë¬¸ì„œ ê°ì²´ ìƒì„±
        doc = Document(
            page_content=content,
            metadata={
                "source": "ì·¨ì—…ê·œì¹™(2025)",
                "article_title": title,
                "category": "ê·œì •" # í•„ìš”ì‹œ ì¹´í…Œê³ ë¦¬ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
            }
        )
        documents.append(doc)
        
    return documents

def ingest_data():
    print(f"ğŸš€ ë°ì´í„° íŒŒì‹± ì‹œì‘... (Namespace: {NAMESPACE})")
    
    # 1. ë°ì´í„° íŒŒì‹±
    file_path = "rules.txt"
    if not os.path.exists(file_path):
        print("âŒ rules.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    docs = parse_rules(file_path)
    print(f"âœ… ì´ {len(docs)}ê°œì˜ ì¡°í•­(Chunk)ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   - ì˜ˆì‹œ: {docs[0].page_content[:50]}...")

    # 2. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 3. Pineconeì— ì—…ë¡œë“œ (LangChain Wrapper ì‚¬ìš©)
    # ê¸°ì¡´ ë°ì´í„° ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´, í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ë¹„ìš°ëŠ” ë¡œì§ì€ Pinecone í´ë¼ì´ì–¸íŠ¸ë¡œ ì§ì ‘ ì²˜ë¦¬í•˜ê±°ë‚˜
    # ë®ì–´ì“°ê¸° ë¡œì§ì„ ê³ ë¯¼í•´ì•¼ í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” Upsert ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
    
    print("ğŸ“¡ Pinecone ì—…ë¡œë“œ ì¤‘...")
    
    vector_store = PineconeVectorStore.from_documents(
        documents=docs,
        embedding=embeddings,
        index_name=INDEX_NAME,
        namespace=NAMESPACE
    )
    
    print("ğŸ‰ ì—…ë¡œë“œ ì™„ë£Œ!")

if __name__ == "__main__":
    ingest_data()